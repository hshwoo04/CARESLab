\documentclass{article}
\usepackage{graphicx, caption, subcaption, verbatim, moreverb, alltt, algorithm2e, kotex}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{fancyvrb}
\usepackage{hhline}
\usepackage{multirow}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\let\verbatiminput=\verbatimtabinput

\setlength{\oddsidemargin}{0.25in}	% 1.25in left margin 
\setlength{\evensidemargin}{0.25in}	% 1.25in left margin (even pages)
\setlength{\topmargin}{0.0in}		% 1in top margin
\setlength{\textwidth}{6.0in}		% 6.0in text - 1.25in rt margin
\setlength{\textheight}{9in}		% Body ht for 1in margins
\addtolength{\topmargin}{-\headheight}	% No header, so compensate
\addtolength{\topmargin}{-\headsep}	% for header height and separation

\begin{document}

\title{Lab 8: Implementing Branch Predictor}   % type title between braces
\author{CSE 4190.308 Computer Architecture \\ 3 Exercises (Total 90 Points) }         
\date{Received: May 27, 2013 \\Due: 11:59 p.m., June 10, 2013\\ \ \\ TA Office
Hours: 7:00 - 8:00 p.m., 6/5 - 6/7}    % type date between braces
\maketitle

\section{Introduction}
In this lab, you will implement caches between the 6-stage pipelined
processor and the main memory. A 6-staged pipelined implementation
with a skeleton code for the caches will be provided.
You will notice that when you run the provided code without any
modifications, it will take a very long time to finish. This is
because the simulated main memory that is accessed in case of cache
misses is made slower, in order to make it a bit more realistic.


\section{Getting Started}

\subsection{How to Download the Source Code}
Download the \texttt{add-lab8.sh} script from the course web page and run it with your ID.

\begin{Verbatim}[frame=single]
   $ ./add-lab8.sh YOUR_ID
\end{Verbatim}

\subsection{Directory Structure of Lab 8}
Lab 8 실습의 디렉터리 구조는 다음과 같습니다.

\begin{Verbatim}[frame=single]
lab5/
    src/	
        LocalCache.bsvv
        CacheTypes.bsv
        Proc.bsv
        smips
    lib/
        ...
\end{Verbatim}

\begin{description}
\item [\texttt{src/}]\hfill \ \\
	Lab 8 실습을 진행할 디렉터리입니다.

\item [\texttt{src/LocalCache.bsv}]\hfill \ \\
	Cache 모듈의 뼈대 코드입니다. 이 파일을 수정하여 실습을 진행합니다.

\item [\texttt{src/CacheTypes.bsv}]\hfill \ \\
	Cache 모듈에서 사용할 파라미터를 정의한 파일입니다.

\item [\texttt{src/Proc.bsv}]\hfill \ \\
	6-stage pipeline SMIPS 프로세서이며 메모리에 직접 접근하는 대신 cache를 사용하도록 구현되어 있습니다.

\item [\texttt{src/smips}]\hfill \ \\
	구현한 프로세서를 컴파일하고 벤치마크 프로그램을 실행할 수 있는 스크립트 파일입니다.

\item [\texttt{lib/}]\hfill \ \\
	Lab 에서 구현한 SMIPS 프로세서를 동작시키는 데 필요한 라이브러리 및 프로그램을 포함하고 있습니다.
\end{description}

\subsection{How to Simulate the Design}
Compiling and running the code can be done identically to the previous
labs, using the \texttt{smips} run script.


\subsection{How to Submit Your Design}
Changed files will be uploaded to svn server when you type \texttt{svn commit} command
in your \texttt{lab8/src} directory.

\section{A 6-stage Pipeline with Caches}
제공되는 프로세서 모듈은 메모리 접근 시 cache를 호출하도록 구현되어 있습니다.
그러나 제공되는 cache 모듈이 모든 요청을 즉시 메모리로 보내기 때문에
cache 가 없는 것과 같은 효과를 냅니다.
이번 실습에서는 이 cache 모듈을 수정하여 정상적으로 동작하는 cache를 구현해야 합니다.
먼저 direct-mapped cache를 구현하고 이를 바탕으로
cache의 block size와 associativity 를 늘리는 실습을 진행합니다.

\subsection{Communication Between Cache and Memory Modules}
제공되는 cache와 메모리 모듈의 인터페이스는 다음과 같습니다.

\begin{Verbatim}[frame=single]
interface Cache;
	method Action req(MemReq r);
	method ActionValue#(Data) resp;

  	method ActionValue#(CacheMemReq) memReq;
  	method Action memResp(Line r);
	
	method Data getMissCnt;
	method Data getTotalReq;
endinterface

interface Memory;
	method Action iReq(CacheMemReq r);
	method ActionValue#(MemResp) iResp;
	method Action dReq(CacheMemReq r);
	method ActionValue#(MemResp) dResp;
endinterface
\end{Verbatim}

\noindent\texttt{Cache}는 각각 \texttt{req}와 \texttt{resp} method를 통해 프로세서로부터 요청를 받고, 그 요청에 대한 답변을
보내게 됩니다. 요청에서 인자로 받는 \texttt{MemReq} 구조체는 \texttt{lib/common-lib/MemTypes.bsv}에 정의 되어 있으며,
request의 종류 (Store인지, Load인지), 메모리 주소, 그리고 store 시에 사용할 데이터가 포함됩니다.
\texttt{Memory} 역시 \texttt{Cache}와 유사한 request-response 방식의 인터페이스로 구성되어 있습니다.
Cache에서 요청받은 작업을 처리하다보면 메모리로의 접근이 필요할 것입니다.
이 때는 \texttt{memReq} method를 통해 \texttt{CacheMemReq}를 메모리 모듈에 전달하고, 
전달한 request가 load인 경우 \texttt{memResp} method를 통해 요청한 데이터를 받아오면 됩니다. 
\\\\
이번 lab에서 사용할 메모리는 cache에서 한번에 다루는 데이터 크기(\textit{Cache Block})가
Load/Store instruction에서 다루는 데이터 크기(\textit{Word})보다 큰 경우를 고려하여 burst access를 지원합니다.
실제의 메모리 동작과는 차이가 있지만, 사용할 메모리는 request에 한번에 읽어올 word의 개수를 지정할 수 있습니다.
\texttt{lib/common-lib/MemTypes.bsv}에 정의된 \texttt{CacheMemReq} 구조체의 \texttt{burstLength}가 그것입니다.
메모리는 \texttt{burstLength}에 따라 순서대로 \texttt{Vector\#(n, Data)}의 구조로 데이터를 전해주게 됩니다.
\\\\
cache와 메모리는 프로세서 모듈인 \texttt{mkProc}에서 선언되어 초기화 됩니다.
cache와 메모리가 서로 같은 레벨에 존재하기 때문에 cache가 메모리의 interface를 부를 수 없고,
메모리가 cache의 interface를 사용할 수 없습니다. 이렇게 같은 레벨의 모듈을 서로 연결할 때, Bluespec에서는 \texttt{mkConnection}이란 모듈을 사용합니다. 
\\\\
현재 cache와 메모리의 작동 메커니즘은 아래와 같습니다 (iCache의 경우).
\\\\
1. CPU가 \texttt{Cache} 인터페이스의 \texttt{req} method를 호출
\\\\
2. iCache가 요청받은 내용을 \texttt{CacheMemReq}로 변환하고 이 request data를 \texttt{memReqQ}에 enqueue
\\\\
3. iCache의 \texttt{memReq} method를 통해 \texttt{memReqQ}에서 request data가 빠져나감
\\\\
4. Memory의 \texttt{iReq} method를 통해 위의 request data가 메모리 모듈의 \texttt{iMemReqQ}로 enqueue
\\\\
5. Memory가 요청을 처리 후, Load 요청인 경우 \texttt{iMemRespQ}에 response data를 enqueue
\\\\
6. Memory의 \texttt{iResp} method를 통해 \texttt{iMemRespQ}에서 response data가 빠져나감
\\\\
7. iCache의 \texttt{memResp} method를 통해 \texttt{memRespQ}로 response data가 enqueue
\\\\
8. iCache가 \texttt{memRespQ}에서 response data를 dequeue하여 얻어냄
\\\\

\noindent 문제는 iCache와 Memory는 서로 interface를 호출할 수 없기 때문에, 3, 4, 6, 7은 상위 모듈인 \texttt{mkProc}에서 다음과 같이 처리해주어야 합니다.

\begin{Verbatim}[frame=single]
rule connectReq;
	let req <- iCache.memReq;
	mem.iReq(req);	
endrule

rule connectResp;
	let resp <- mem.iResp;
	iCache.memResp(resp);
endrule
\end{Verbatim}
\noindent 이처럼 단순히 \texttt{ActionValue} method와 \texttt{Action} method를 잇는 rule을 일일이 만들지 않도록 

\begin{Verbatim}[frame=single]
mkConnection(mem.iReq, iCache.memReq);
mkConnection(mem.iResp, iCache.memResp);
\end{Verbatim}

\noindent 위와 같은 코드를 이용하면 \texttt{mkConnection}모듈이 위 rule의 동작을 자동으로 수행하게 됩니다.
이러한 연결은 이미 \texttt{Proc.bsv}에 구현되어 있으므로, 여러분들은 cache에서 메모리에 request를 보낼때는
\texttt{memReqQ}에 request data를 enqueue하고 메모리로 부터 response를 받는 것은 \texttt{memRespQ}에 데이터가 enqueue되기를 기다리면 됩니다.
\\\\
예를 들어, 메모리로 부터 \texttt{0xF0} 번째 부터 4개의 word를 읽어오고 싶다면

\begin{Verbatim}
memReqQ.enq(CacheMemReq{op: Ld, addr: 0xF0, data: ?, burstLength: 4});
\end{Verbatim}
위와 같은 코드를 어떤 rule에서 실행 한 후 다른 rule에서는

\begin{Verbatim}
let resp = memResp.first;
\end{Verbatim}
위와 같은 코드로 response를 기다리면 됩니다. 그리고 return 값인 \texttt{resp}에는 앞에서 부터 순서대로 \texttt{0xF0, 0xF4, 0xF8, 0xFC}의 데이터가 저장되어 있습니다.


\subsection{Implementing Direct-mapped Cache Memory}
강의자료와 \texttt{CACA Book} 을 참고하여 block size 가 1 word (\texttt{Data}) 인
가장 간단한 형태의 direct-mapped cache 를 구현합니다.

cache access 와 miss 수는 각 cache 모듈의 상단에 선언된
\texttt{missCnt}, \texttt{reqCnt} 레지스터를 사용하여 count 할 수 있습니다.
이 값은 벤치마크 프로그램 수행 종료 시에 화면에 출력됩니다.

\noindent \paragraph{\bf Exercise 1 (30 points) :} \texttt{LocalCache.bsv} 파일을 수정하여
\texttt{mkCacheDirectMap} 모듈이 single-word direct-mapped cache로 동작하도록 완성하시오.
\\\\
정확히 구현한 경우 benchmark 시뮬레이션 시 아래표와 유사한 결과를 얻을 수 있습니다. 

\begin{table}[h]
\centering
\begin{tabular}{|r|c|c|c|c|}
\hline
Benchmark & Clock Cycles & Insts & I-Cache Miss Rate & D-Cache Miss Rate \\
\hline
towers & 31796 & 9907 & 21.2\% & 6.3\% \\
 vvadd & 11593 & 3018 & 1.0\% & 100\% \\
multiply & 75050 & 21098 & 0.1\% & 100\%\\
  median & 20624 & 6871 & 0.7\% & 50.4\% \\
   qsort & 65577 & 21626 & 0.6\% & 24.6\% \\
\hline
\end{tabular}
\caption{Benchmark Result with Direct-mapped Cache}
\end{table}

\subsection{Increasing Block Size}
Single-word block cache 에서는 메모리 Instruction 요청한 데이터만 cache로 읽어와 저장하는데,
cacche 의 block size 를 늘리면 instruction 에서 요청하는 데이터보다 많은 데이터를 읽어와
cache 에 저장함으로써 성능향상을 기대할 수 있습니다.
이는 대부분의 프로그램이 메모리 접근 패턴에서 spatial locality 특성을 보이기 때문입니다.
메모리 주소상으로 인접해있는 데이터를 접근할 확률이 높고 이 데이터를 미리 한꺼번에 
읽어옴으로써 cache hit rate 을 증가시킬 수 있습니다.

\noindent \paragraph{\bf Exercise 2 (30 points) :} 
\textbf{Exercise 1} 에서 구현했던 single-word direct-mapped cache 를 수정하여
multiple-word block size 를 지원하는 direct-mapped cache 를 구현하시오
(단, cache 의 전체 크기는 변경하지 않음). block size 는 다음과 같이
\texttt{typedef} 를 통해 정의하여 자유롭게 변경할 수 있도록 구현해야 합니다.
Cache 모듈과 관련된 정의들은 \texttt{CacheTypes.bsv} 파일에 있습니다.

\begin{Verbatim}[frame=single]
  typedef WordsPerBlock 4
\end{Verbatim}

\newpage
\다음은 block size를 4-word로 설정하고 benchmark 프로그램을 실행시킨 결과입니다.

\begin{table}[ht]
\centering
\begin{tabular}{|r|c|c|c|c|}
\hline
Benchmark & Clock Cycles & Insts & I-Cache Miss Rate & D-Cache Miss Rate \\
\hline
towers & 27170 & 9905 & 7.35\% & 10.59\%\\
 vvadd & 8787 & 3019 & 0.33\% & 50.44\% \\
multiply & 73992 & 21098 & 0.03\% & 51.30\% \\
  median & 19232 & 6870 & 0.20\% & 31.71\% \\
   qsort & 62561 & 21627 & 0.16\% & 11.60\% \\
\hline
\end{tabular}
\caption{Benchmark Result with 4-word block, 2-way Set Associative Cache}
\end{table}


\section{Collecting Instruction Statistics}
Pipelined Processor가 가장 높은 성능을 내는 경우는 프로그램 수행의 처음과 끝 부분을 제외한 
모든 cycle에서 모든 stage가 동작하고 있는 상황일 것입니다. 하지만 다양한 원인들로 인해 이러한 상황을 가지기 어려워 지는데,
그 원인들 중 하나가 Jump 또는 Branch 명령어 처리 시 잘못된 pc 값 계산으로 인한 stall의 발생 입니다. 또는 일반적으로
여러 cycle이 걸리는 메모리 접근이 빈번한 프로그램의 경우, 메모리의 응답을 기다리느라 전체 수행 cycle이 증가할 수 있습니다.
\\따라서 Pipelined Processor의 성능 분석에 있어서 프로그램의 메모리 접근 비율(Ld, St 명령어의 비율) 또는 Branch 명령어 처리 
시 잘못된 pc 값 사용 비율 등은 성능에 영향을 크게 미치는 중요한 요소입니다. 이와 같은 비율 정보를 얻을 수 있다면 
성능 저하의 원인이 어디에서 오는지 짐작하여 적합한 최적화 방법을 도출할 수 있을 것입니다. 
\\이를 위해 Lab의 나머지 부분에서는 여러분이 완성한 three-stage pipeline processor에서,
benchmark를 수행하면서 명령어의 정보를 수집하는 과정을 다루도록 하겠습니다.

\subsection{Increasing Associativity}
cache 의 associativity 는 특정 메모리 주소값의 데이터가 cache 에 들어갈 때
어느 위치에 저장될 수 있는지, 그 제한된 공간의 수를 의미합니다.
associativity 가 1인 direct-mapped cache 는 임의의 주소값의 데이터가
cache 내에서 한 곳에만 위치할 수 있습니다. 다시 말해 associativity 가 n 인
cache 는, 임의의 주소값의 데이터가 특정 n 개의 cache entry 중 하나에 선택적으로 위치할 수 
있는 구조입니다. 

Set associative cache 를 구현하려면, set 내에 더이상 공간이 없는데 새 데이터를 저장해야
할 때 cache 에서 쫓아낼 victim 을 선정하는 알고리즘을 결정해야 합니다.
가장 먼 과거에 접근되었던 entry 를 쫓아내는 LRU 방식을 생각할 수 있겠으나,
정확한 LRU 를 구현하려면 추가적으로 유지해야 하는 정보의 양이 많고
로직의 복잡도 또한 크게 증가합니다. 따라서 이번 실습에서는 Exact LRU 가 아닌
Approximate LRU 를 적용하여, 가장 최근에 접근했던 entry 를 제외하고 victim 을 선정하는
정책을 취합니다. 2-way set associative cache 의 경우는 이 정책이 Exact LRU 와 동일하며
associativity 가 더 큰 경우에도 다시 접근될 확률이 가장 높은 entry 를 
cache 에서 쫓아내는 상황을 방지할 수 있습니다.

\noindent \paragraph{\bf Exercise 3 (30 points) :} 
위 \textbf{Exercise 2}에서 구현한 multiple-word direct-mapped cache 를 바탕으로,
\texttt{LocalCache.bsv} 파일 하단에 선언되어 있는 \texttt{mkCacheSetAssociative} 모듈에
n-way set associative cache 를 구현하시오.
\texttt{mkCacheSetAssociative} 모듈은 multiple-word block size 와 multi-way 를 모두 지원해야 합니다.
여기서 way의 수는 block size 와 마찬가지로, \texttt{typedef} 를 통해 정의하여
자유롭게 변경이 가능하도록 구현해야 합니다.

\newpage
예를 들어, block size가 4-word인 2-way set associative cache는 다음과 같은 결과를 보입니다.

\begin{table}[ht]
\centering
\begin{tabular}{|r|c|c|c|c|}
\hline
Benchmark & Clock Cycles & Insts & I-Cache Miss Rate & D-Cache Miss Rate \\
\hline
towers & 18001 & 9906 & 0.55\% & 2.21\%\\
 vvadd & 8787 & 3019 & 0.33\% & 50.44\% \\
multiply & 73992 & 21098 & 0.03\% & 51.30\% \\
  median & 19232 & 6870 & 0.20\% & 31.71\% \\
   qsort & 62234 & 21627 & 0.17\% & 10.50\% \\
\hline
\end{tabular}
\caption{Benchmark Result with 4-word block, 2-way Set Associative Cache}
\end{table}
\end{document}
